\onehalfspacing
\chapter{Основные понятия и термины}
\section{Машинное обучение}
Теория машинного обучения зародилась практически одновременно с появлением первых компьютеров и на
протяжении последних 70 лет является активно развивающейся дисциплиной. Ее постоянное развитие вызвано
ростом возможностей современных вычислительных систем, еще более стремительным ростом объемов данных,
доступных для анализа, а также постоянным расширением области применения методов машинного обучения на
все более широкий класс задач обработки данных.

Определение машинного обучения, данное Томом М.~Митчеллом:
\begin{quotation}
\vspace*{-1ex}
машина \emph{обучается} на основе опыта \( E \) по отношению к некоторому классу задач \( T \) и меры
качества \( P \), если качество решения задач из класса \( T \), измеренное на основе \( P \),
улучшается с приобретением опыта \( E \).
\end{quotation}

Различают два типа обучения. Обучение \emph{по прецедентам}, или \emph{индуктивное} обучение, основано
на выявлении общих закономерностей по частным эмпирическим данным. \emph{Дедуктивное} обучение
предполагает формализацию знаний экспертов и их перенос в компьютер в виде базы знаний. Дедуктивное
обучение принято относить к области экспертных систем, поэтому обычно под машинным обучением понимают
обучение по прецедентам.

\section{Обучение по прецедентам}
Пусть задано множество \emph{объектов} \( X \), множество \emph{допустимых ответов} \( Y \), и
существует \emph{целевая функция} \( y^*\colon X \to Y \), значения которой \( y_i = y^*_i (x_i) \)
известны только на конечном подмножестве объектов \( \bigl\{ x_1, \dots, x_\l \bigr\} \subset X \).
Пары <<объект--ответ>> \( \bigl( x_i, y_i \bigr) \) называются \emph{прецедентами}. Совокупность пар
\( X^\l = (x_i, y_i)_{i = 1}^\l \) называется \emph{обучающей выборкой}.

Задача обучения по прецедентам заключается в том, чтобы по выборке \( X^\l \) восстановить зависимость
\( y^* \), то есть построить \emph{решающую функцию} \( a\colon X \to Y \), которая бы приближала
целевую функцию \( y^*(x) \), причем не только на обучающей выборке, но и на всем множестве \( X \).

Решающая функция \( a \) должна допускать эффективную компьютерную реализацию, по этой причине ее также
называют \emph{алгоритмом}.

Объекты обладают различными характеристиками. Результат измерения некоторой характеристики называется
\emph{признаком} \( f \) объекта. Формально, признаком считается отображение \( f\colon X \to D_f \),
где \( D_f \)~--- множество допустимых значений признака. В зависимости от природы множества \( D_f \)
признаки делятся на несколько типов:
\begin{itemize}
  \vspace*{-.8em}
  \itemsep -5pt
  \item если \( D_f = \{ 0, 1 \} \), то \( f \)~--- бинарный признак;
  \item если \( D_f \)~--- конечное множество, то \( f \)~--- номинальный признак;
  \item если \( D_f \)~--- конечное упорядоченное множество, то \( f \)~--- порядковый признак;
  \item если \( D_f = \RE \), то \( f \)~--- количественный признак.
\end{itemize}
Если все признаки имеют одинаковый тип, то исходные данные называются \emph{однородными}, в противном
случае~--- \emph{разнородными}. Совокупность всех признаков объекта называется \emph{описанием}
объекта.

Описание объекта обычно записывается в виде матрицы:
\[
  X =
  \begin{pmatrix}
    x_1^{(1)}  & x_2^{(1)}  & \cdots & x_D^{(1)}  \\
    x_1^{(2)}  & x_2^{(2)}  & \cdots & x_D^{(2)}  \\
    \vdots     & \vdots     & \ddots & \vdots     \\
    x_1^{(\l)} & x_2^{(\l)} & \cdots & x_D^{(\l)}
  \end{pmatrix}\!;\
  Y =
  \begin{pmatrix}
    y^{(1)} \\
    y^{(2)} \\
    \vdots  \\
    y^{(\l)}
  \end{pmatrix}\!;\
  \bigl(X\mid Y\bigr) = \mleft(
  \begin{array}{cccc|c}
    x_1^{(1)}  & x_2^{(1)}  & \cdots & x_D^{(1)}  & y^{(1)} \\
    x_1^{(2)}  & x_2^{(2)}  & \cdots & x_D^{(2)}  & y^{(2)} \\
    \vdots     & \vdots     & \ddots & \vdots     & \vdots  \\
    x_1^{(\l)} & x_2^{(\l)} & \cdots & x_D^{(\l)} & y^{(\l)}
  \end{array}\mright)\!.
\]

\emph{Моделью алгоритмов} называется параметрическое семейство отображений
\( A = \bigl\{g(x,\theta)\mid\theta\in\Theta\bigr\} \), где \( g\colon X\times\Theta\to Y \)~---
некоторая фиксированная функция, \( \Theta \)~--- множество допустимых значений параметра \( \theta \),
называемое \emph{пространством параметров}.

Процесс подбора оптимального параметра модели \( \theta \) по обучающей выборке \( X^\l \) называют
настройкой или \emph{обучением} алгоритма \( a\in A \).

\emph{Метод обучения}~--- это отображение \( \mu\colon (X\times Y)^\l\to A \), которое произвольной
конечной выборке \( X^\l = (x_i, y_i)_{i = 1}^\l \) ставит в соответствие некоторый алгоритм
\( a\in A \). Говорят также, что метод \( \mu \) \emph{строит} алгоритм \( a \) по выборке \( X^\l \).
Метод обучения должен допускать эффективную программную реализацию.

Видно, что задача обучения по прецедентам делится на два этапа:
\begin{itemize}
  \vspace*{-.8em}
  \itemsep -5pt
  \item[] этап \emph{обучения}~--- метод \( \mu \) по выборке \( X^\l \) строит алгоритм
    \( a = \mu(X^\l) \).
  \item[] этап \emph{применения}~--- алгоритм \( a \) для новых объектов \( x \) выдает ответы
    \( y = a(x) \).
\end{itemize}

Этап обучения наиболее сложен. Как правило, он сводится к поиску параметров моделт, доставляющих
оптимальное значение заданному функционалу качества.

\emph{Функционал качества} алгоритма \( a \) на выборке \( X^\l \):
\begin{equation}
  Q(a, X^\l) = \frac{1}{\l}\sum_{i = 1}^\l \L(a, x_i),
  \label{eq:1}
\end{equation}
где \( \L(a, x) \)~--- \emph{функция потерь}~--- неотрицательная функция, характеризующая величину
ошибки алгоритма \( a \) на объекте \( x \).

Если функция потерь принимает только значения 0 (ответ \( a(x) \) корректен) и 1 (ответ \( a(x) \)
ошибочен), то она называется бинарной, а функционал \( Q \) называется \emph{частотой ошибок} алгоритма
\( a \) на выборке \( X^\l \). Примером такой функции потерь может служить индикатор ошибки:
\( \L(a, x) = \bigl[a(x)\ne~y^*(x)\bigr] \), где квадратные скобки обозначают перевод логического
значения в число\linebreak
(\( [\textit{ложь}] =~0 \), \( [\textit{истина}] = 1 \)).

Если функция потерь выражается как отклонение от правильного ответа
\( \L(a, x) = \abs{a(x) - y^*(x)} \), то функционал \( Q \) называется \emph{средней ошибкой} алгоритма
\( a \) на выборке \( X^\l \).

Если функция потерь выражается как квадрат отклонения от правильного ответа
\( \L(a, x) = \bigl(a(x) - y^*(x)\bigr)^2 \), то функционал \( Q \) называется
\emph{средней квадратичной ошибкой} алгоритма \( a \) на выборке \( X^\l \).

Классический метод обучения, называемый \emph{минимизацией эмпирического риска}, заключается в том,
чтобы найти в заданной модели \( A \) алгоритм \( a \), доставляющий минимальное значение функционалу
качества \( Q \) на заданной обучающей выборке \( X^\l \):
\begin{equation}
  \mu\left(X^\l\right) = \arg\min_{a\in A} Q\left(a, X^\l\right).
  \label{eq:2}
\end{equation}

\section{Примеры задач машинного обучения}
\begin{itemize}
  \item[] \textbf{Пример 1}. Имеется база данных о клиентах туристического
    агентства с информацией о возрасте и доходе за месяц. Есть рекламный материал двух видов: более
    дорогой и комфортный отдых и более дешевый, молодежный отдых. Соответственно, определены два класса
    клиентов: класс 1~--- те клиенты, которые уже выбирали для себя более дорогой отдых, и класс 2~---
    те, что выбирали молодежный вариант.
    Необходимо определить, к какому классу принадлежит новый клиент и какой из двух видов рекламных
    материалов ему стоит отсылать.
  \item[] \textbf{Пример 2}. Имеется база данных о доходах торговой сети и о товарах, продаваемых ею, за
  определенный период времени. О товарах известна их цена и объем продаж за период. Для повышения доходов
  торговой сети за следующий период времени, требуется определить: влияние цены товара на его спрос,
  товары, продажи которых сильно влияют на общий доход   торговой сети, и товары, спрос на которые
  довольно низок и они мало влияют на доход торговой сети. Затем необходимо сделать прогноз на доход за
  следующий период времени, если произвести корректировку   каталога товаров, продаваемых торговой сетью,
  и цен на них.
  \item[] \textbf{Пример 3}. Имеется база данных о количестве жителей в домах города. Необходимо определить
  в каких местах оптимальнее всего размещать остановки общественного транспорта.
\end{itemize}

\chapter{Технология применения}
\section{Вероятностная постановка задачи обучения}
В задачах обучения по прецедентам элементы множества \( X \)~--- это не реальные объекты, а лишь
доступные данные о них. Данные могут быть неточными, поскольку измерения значений признаков
\( f_j(x) \) и целевой зависимости \( y^*(x) \) обычно выполняются с погрешностями. Данные могут быть
неполными, поскольку измеряются не все мыслимые признаки, а лишь физически доступные для измерения.
В результате одному и тому же описанию \( x \) могут соответствовать различные объекты и различные
ответы. В таком случае \( y^*(x) \), строго говоря, не является функцией. Устранить эту некорректность
позволяет вероятностная постановка задачи.

Вместо существования неизвестной целевой зависимости \( y^*(x) \) предположим существование
неизвестного вероятностного распределения на множестве \( X\times Y \) с плотностью \( p(x, y) \), из
которого случайно и независимо выбираются \( \l \) наблюдений \( X^\l = (x_i, y_i)^\l_{i = 1} \). Такие
выборки называются простыми или случайными одинаково распределенными.

Вероятностная постановка задачи считается более общей, так как функциональную зависимость \( y^*(x) \)
можно представить в виде вероятностного распределения \( p(x, y) = p(x)p(y|x) \), положив
\( p(y|x) = \d(y - y^*(x)) \), где \( \d(z) \)~--- дельта-функция.

\subsection{Принцип максимума правдоподобия}
При вероятностной постановке задачи вместо модели алгоритмов \( g(x, \theta) \), аппроксимирующей
неизвестную зависимость \( y^*(x) \), задается модель совместной плотности распределения объектов и
ответов \( \phi(x, y, \theta) \), аппроксимирующая неизвестную плотность \( p(x, y) \). Затем
определяется значение параметра \( \theta \), при котором выборка данных \( X^\l \) максимально
правдоподобна, то есть наилучшим образом согласуется с моделью плотности.

Если наблюдения в выборке \( X^\l \) независимы, то совместная плотность распределения всех наблюдений
равна произведению плотностей \( p(x, y) \) в каждом наблюдении:
\( p(X^\l) = p\bigl((x_1, y_1), \ldots , (x_\l, y_\l)\bigr) = p(x_1, y_1)\cdot\ldots\cdot
p(x_\l, y_\l) \). Подставляя вместо \( y^*(x) \) модель плотности
\( \phi(x, y, \theta) \), получаем функцию правдоподобия:
\begin{equation}
  L(\theta, X^\l) = \prod_{i = 1}^\l \phi\left(x_i, y_i, \theta\right).
  \label{eq:3}
\end{equation}

Чем выше значение правдоподобия, тем лучше выборка согласуется с моделью. Значит, нужно искать значение
параметра \( \theta \), при котором значение \eqref{eq:3} максимально. В математической статистике это
называется принципом максимума правдоподобия.

После того, как значение параметра \( \theta \) найдено, искомый алгоритм \( a_\theta(x) \) несложно
строится по плотности \( \phi(x, y, \theta) \).

\subsection{Связь максимизации правдоподобия с минимизацией эмпирического риска}
Вместо максимизации \( L \) удобнее минимизировать функционал \( -\ln L \), поскольку он аддитивен
(имеет вид суммы) по объектам выборки:
\begin{equation}
  -\ln L\left(\theta, X^\l\right) = -\sum_{i = 1}^\l \ln\phi\left(x_i, y_i, \theta\right)
  \to\min_{\theta}.
  \label{eq:4}
\end{equation}

Этот функционал совпадает с функционалом эмпирического риска \eqref{eq:1}, если определить
вероятностную функцию потерь \( \L\left(a_\theta, x\right) = -\l\ln\phi(x, y, \theta) \). Такое
определение потери вполне естественно~--- чем хуже пара \( (x_i, y_i) \) согласуется с моделью
\( \phi \), тем меньше значение плотности \( \phi(x_i, y_i, \theta) \) и выше величина потери
\( \L (a_\theta, x) \).

Верно и обратное~--- для многих функций потерь возможно подобрать модель плотности
\( \phi(x, y, \theta) \) таким образом, чтобы минимизация эмпирического риска была эквивалентна
максимизации правдоподобия.

\subsection{Проблема переобучения и понятие обобщающей способности}
Если минимум функционала \( Q(a, X^\l) \) достигается на алгоритме \( a \), то это еще не гарантирует,
что \( a \) будет хорошо приближать целевую зависимость на произвольной контрольной выборке
\( X^k = (x'_i, y'_i)^k_{i = 1} \).

Когда качество работы алгоритма на новых объектах, не вошедших в состав обучения, оказывается
существенно хуже, чем на обучающей выборке, говорят об эффекте переобучения или переподгонки. При
решении практических задач с этим явлением приходится сталкиваться очень часто.

Легко представить себе метод, который минимизирует эмпирический риск до нуля, но при этом абсолютно не
способен обучаться. Получив обучающую выборку \( X^\l \), он запоминает ее и строит алгоритм, который
сравнивает предъявляемый объект \( x \) с обучающими объектами \( x_i \) из \( X^\l \). В случае
совпадения \( x = x_i \) алгоритм выдает правильный ответ \( y_i \). Иначе выдается любой другой ответ.
Эмпирический риск принимает наименьшее возможное значение, равное нулю. Однако этот алгоритм не
способен восстановить зависимость вне материала обучения. Отсюда вывод: для успешного обучения
необходимо не только запоминать, но и обобщать.

Обобщающая способность метода \( \mu \) характеризуется величиной\linebreak
\( Q\left(\mu\left(X^\l\right), X^k\right) \) при условии, что выборки \( X^\l \) и \( X^k \) являются
представительными. Для формализации понятия <<представительная выборка>> обычно принимается стандартное
предположение, что выборки \( X^\l \) и \( X^k \)~--- простые, полученные из одного и того же
неизвестного вероятностного распределения на множестве~\( X \).

\section{Этапы разработки алгоритмов машинного обучения}
\begin{enumerate}
  \itemsep-5pt
  \item Сбор данных. Существует бесчисленное множество способов сбора данных. Также можно использовать
    публично доступные данные.
  \item Подготовка входных данных. Необходимо убедиться что они находятся в пригодном для использования
    виде.
  \item Анализ входных данных. В данных можно увидеть некоторые закономерности. Однако, могут быть
    элементы, значительно отличающихся от общей массы. Возможно, в данных есть лишние и недостоверные
    прецеденты, которые необходимо удалить.
  \item Обучение алгоритма. На этом этапе машина проходит обучение. Алгоритм обрабатывает данные,
    полученные на 1--3 этапах, и выдает информацию или знания. В случае использования обучения без
    учителя этот шаг пропускается.
  \item Тестирование алгоритма. На этом шаге находит применение информация, полученная на предыдущем
    этапе. Во время тестирования алгоритм проходит проверку~--- насколько хорошо он справляется со
    своей задачей. В случае обучения с учителем есть некоторые известные значения, которые можно
    использовать для проверки. В случае обучения без учителя, придется использовать другие методики
    тестирования качества работы алгоритма. Если алгоритм не проходит проверку, то происходит возврат к
    шагу~4 для коррекции метода обучения. Если проблема кроется в данных, то происходит возврат к
    шагу~1.
  \item Использование результата. На этом шаге на основе алгоритма разрабатывается работающая
    программа.
\end{enumerate}

\chapter{Задачи машинного обучения}
Общая постановка задачи обучения по прецедентам:
\begin{quotation}
\vspace*{-1ex}
дано конечное множество прецедентов, по каждому из которых измерены некоторые данные. Требуется по этим
частным данным выявить общие зависимости, закономерности, взаимосвязи, присущие не только этой
конкретной выборке, но вообще всем прецедентам, в том числе тем, которые еще не наблюдались.
\end{quotation}

Для решения задачи обучения по прецедентам в первую очередь фиксируется модель восстанавливаемой
зависимости. Затем вводится функционал качества, значение которого показывает, насколько хорошо модель
описывает наблюдаемые данные. Алгоритм обучения ищет такой набор параметров модели, при котором
функционал качества на заданной обучающей выборке принимает оптимальное значение. Процесс настройки
модели по выборке данных в большинстве случаев сводится к применению численных методов оптимизации.

В основном все стандартные задачи можно разделить на три типа:
\begin{itemize}
  \vspace*{-1ex}
  \itemsep -5pt
  \item обучение \emph{с учителем};
  \item обучение \emph{без учителя};
  \item \emph{частичное} обучение.
\end{itemize}

\section{Задачи обучения с учителем}
В задачах обучения с учителем каждый прецедент представляет собой стандартную пару <<объект--ответ>>.
Требуется найти функциональную зависимость ответов от описаний объектов и построить алгоритм,
принимающий на входе описание объекта и выдающий на выходе ответ. Функционал качества в таких задачах
обычно определяется как средняя ошибка ответов, по всем объектам выборки.

Среди задач обучения с учителем можно выделить отдельные подтипы задач:
\begin{itemize}
  \vspace*{-1ex}
  \itemsep -5pt
  \item задачи \emph{классификации}. Они отличаются тем, что множество допустимых ответов конечно. Их
    называют метками классов, а классом называют множество всех объектов с данным значением метки.
    
    \begin{quote}
      \vspace*{-1ex}
      Дано некоторое множество объектов \( X \) и конечное множество номеров классов \( Y \). Известно,
      что существует неизвестная целевая зависимость \( f^*\colon X\to Y \), значения которой известны
      только на объектах обучающей выборки. Задача заключается в построении алгоритма
      (\emph{классификатора}), способного классифицировать произвольный объект \( x\in X \).
      \vspace*{-1ex}
    \end{quote}
        
    В задаче классификации могут быть следующие типы входных данных:
    \begin{enumerate}
       \item признаковые описания (каждый объект описывается каким-либо набором признаков~---
         характеристик);
       \item матрица расстояний (для каждого объекта известно расстояние от него до всех других
         объектов);
       \item временной ряд (последовательность измерений во времени).
    \end{enumerate}

    Любые сложные входные данные, такие как графы, изображения, видеозаписи, запросы к БД и~т.~п.
    приводятся к перечисленным трем.

    В качестве реальных примеров задачи классификации можно привести:
    \begin{itemize}
      \item распознавание образов (лиц). Классы~--- личности.
      \item Распознавание рукописного текста. Классы~--- символы.
      \item Определение спама в электронной почте. Классы~--- спам, не спам.
      \item Кредитный скоринг (в упрощенном варианте). Классы~--- платежеспособен, не платежеспособен.
    \end{itemize}
   
  \item Задачи \emph{восстановления регрессии} отличаются тем, что допустимым ответом является
    действительное число или числовой вектор.
    
    \begin{quote}
      \vspace*{-1ex}
      Дано некоторое множество объектов \( X \) и множество номеров классов \( Y \). Причем
      \( \abs{Y} = \abs{\RE} \), где \( \RE \)~--- множество действительных чисел.
      Известно, что существует неизвестная целевая зависимость \( f^*\colon X\to Y \), значения которой
      известны только на объектах обучающей выборки. Задача заключается в построении алгоритма,
      способного классифицировать произвольный объект \( x\in X \).
      \vspace*{-1ex}
    \end{quote}
    
    Можно с некоторым допущением сказать, что задача восстановления регрессии это задача классификации
    с множеством классов \( \RE \). Очень многие задачи классификации несложным образом
    модифицируются под восстановление регрессии.
    
    В качестве реальных примеров задачи восстановления регрессии можно привести:
    \begin{itemize}
      \item кредитный скоринг. Оценка максимальной суммы кредита.
      \item Продажи. Оценка объемов продаж.
    \end{itemize}
    
  \item Задачи \emph{прогнозирования} отличаются тем, что объектами являются отрезки временных рядов,
    обрывающиеся в тот момент, когда требуется сделать прогноз на будущее.
    
    \begin{quote}
      \vspace*{-1ex}
      Дано множество \( X \), являющееся временным рядом (т.~е. множество некоторых значений
      функции во времени). Задача заключается в нахождении значений функции за пределами данных,
      имеющихся в \( X \).
      \vspace*{-1ex}
    \end{quote}
    
    Задача прогнозирования может решаться методами решения задач классификации и восстановления
    регрессии и является самой популярной задачей машинного обучения.
    
    В качестве реальных примеров задачи прогнозирования можно привести:
    \begin{itemize}
      \item сейсмопредсказания. Прогнозирование времени следующего землетрясения на определенной
        территории.
      \item Изменение стоимости. Прогнозирование стоимости какого-либо продукта в определенный
        промежуток времени.
      \item Нагрузка на call-центр. Прогнозирование количества телефонных звонков клиентов компании.
    \end{itemize}
\end{itemize}

\section{Задачи обучения без учителя}
В задачах обучения без учителя ответы не задаются, и требуется
искать зависимости между объектами.

Среди задач обучения без учителя можно выделить отдельные
подтипы задач:
\begin{itemize}
  \vspace*{-1ex}
  \itemsep -5pt
  \item задачи \emph{кластеризации}. Их суть заключается в том, чтобы сгруппировать объекты в кластеры,
    используя данные о попарном сходстве объектов.
    
    \begin{quote}
      \vspace*{-1ex}
      Дано некоторое множество объектов \( X \). Задача заключается в построении алгоритма, способного
      относить произвольный объект \( x\in X \) к некоторому кластеру. Кластером мы будем называть
      аналог класса в задаче классификации с той разницей, что кластеры изначально неизвестны.
      \vspace*{-1ex}
    \end{quote}
    
    Кластеры, как правило, обладают следующими свойствами:
    \begin{enumerate}
      \item непересекаемость~--- никакие два кластера не имеют общих элементов;
      \item конечность каждого кластера;
      \item связность~--- никакой кластер невозможно разбить на два непустых непересекающихся открытых
        подмножества.
    \end{enumerate}
    
    В качестве реальных примеров задачи кластеризации можно привести:
    \begin{itemize}
      \item группировка текстов. Кластеры~--- тематики текстов.
      \item Разделение людей по психотипу. Кластеры~--- психотипы.
      \item Любая задача классификации без обучающей выборки.
    \end{itemize}
    
  \item Задачи \emph{поиска ассоциативных правил}. В них данные представляются в виде признаковых
    описаний, а найти требуется такие наборы признаков, и такие значения этих признаков, которые в
    описаниях встречаются особенно часто.
    
    \begin{quote}
      \vspace*{-1ex}
      Дано некоторое множество объектов \( X \). Задача заключается в построении алгоритма, способного
      находить взаимосвязи между элементами \( X \).
      \vspace*{-1ex}
    \end{quote}
    
    В качестве реальных примеров задачи поиска ассоциативных правил можно привести:
    \begin{itemize}
      \item анализ рыночных корзин. Поиск наиболее типичных шаблонов покупок в супермаркетах.
      \item Анализ поведения пользователя. Отличающиеся от большинства элементы будут подозреваемыми во
        вторжении.
    \end{itemize}
    
  \item Задачи \emph{фильтрации выбросов} чем-то схожи с задачами поиска ассоциативных правил, только в
    них необходимо найти нетипичные объекты, имеющие признаки или комбинации признаков, встречающихся
    реже других;
  \item задачи \emph{построения доверительной области}~--- области минимального объема с гладкой
    границей, содержащей заданную долю выборки;
  \item задачи \emph{сокращения размерности}. Их суть заключается в том, чтобы по исходным признакам с
    помощью некоторых функций преобразования перейти к наименьшему числу новых признаков, не потеряв
    при этом никакой существенной информации об объектах.
    
    \begin{quote}
      \vspace*{-1ex}
      Дано некоторое множество объектов \( X \), представляющее собой декартово произведение
      \( Y\times Y\times\ldots\times Y \). Задача заключается в сокращении размерности множества
      \( X \) с минимальной потерей качества данных.
      \vspace*{-1ex}
    \end{quote}
    
    Практическая польза данной задачи очевидна. С данными больших размерностей трудно работать. Решение
    задачи позволяет повысить эффективность работы с ними.
  \item Задачи \emph{заполнения пропущенных значений}~--- замена
    недостающих признаков у объектов их прогнозными значениями;    
  \item В задачи \emph{ранжирования} ответы надо получить сразу на множестве объектов, после чего
    отсортировать их по значениям ответов.
    
    \begin{quote}
      \vspace*{-1ex}
      Дана пара <<запрос--объект>>. Задача заключается в определении релевантности объекта запросу.
      \vspace*{-1ex}
    \end{quote}
    
    Обычно, задача ранжирования решается статистически, но существуют и обучаемые методы.
    
    В качестве реальных примеров задачи ранжирования можно привести:
    \begin{itemize}
      \item ранжирование поисковых запросов пользователя;
      \item ранжирование в системах коллаборативной фильтрации (целевые рекомендации).
    \end{itemize}
\end{itemize}

\section{Другие виды обучения}
Частичное обучение занимает промежуточное положение между обучением с учителем и без учителя. Каждый
прецедент представляет собой пару <<объект, ответ>>, но ответы известны только на части прецедентов.

Также есть и другие виды задач обучения, которые нельзя отнести к перечисленным трем типам задач:
\begin{itemize}
  \vspace*{-1ex}
  \itemsep -5pt
  \item \emph{трансдуктивное} обучение. Дана конечная обучающая выборка прецедентов. Требуется по этим
    частным данным сделать предсказания относительно других частных данных~--- тестовой выборки. В
    отличие от стандартной постановки, здесь не требуется выявлять общую закономерность, поскольку
    известно, что новых тестовых прецедентов не будет;
  \item обучение \emph{с подкреплением}. Роль объектов играют пары <<ситуация, принятое решение>>,
    ответами являются значения функционала качества, характеризующего правильность принятых решений.
    Как и в задачах прогнозирования, здесь существенную роль играет фактор времени;
  \item \emph{динамическое} обучение может быть как обучением с учителем, так и без учителя. Специфика
    в том, что прецеденты поступают потоком. Требуется немедленно принимать решение по каждому
    прецеденту и одновременно доучивать модель зависимости с учетом новых прецедентов. Как и в задачах
    прогнозирования, здесь существенную роль играет фактор времени;
  \item \emph{активное} обучение отличается тем, что обучаемый имеет возможность самостоятельно
    назначать следующий прецедент, который станет известен;
  \item \emph{метаобучение} отличается тем, что прецедентами являются ранее решенные задачи обучения.
    Требуется определить, какие из используемых в них эвристик работают более эффективно. Конечная
    цель~--- обеспечить постоянное автоматическое совершенствование алгоритма обучения с течением
    времени.
\end{itemize}

Прикладные задачи классификации, регрессии, кластеризации и прогнозирования встречаются в самых разных
областях человеческой деятельности, и их число постоянно растет.

\chapter{Основные методы машинного обучения}
\section{Задачи классификации}
\subsection{<<Наивный>> байесовский классификатор}

Байесовский подход является классическим в теории распознавания образов и лежит в основе многих
методов. Он опирается на теорему о том, что если плотности распределения классов известны, то алгоритм
классификации, имеющий минимальную вероятность ошибок, можно выписать в явном виде.

Итак, пусть \( X \)~--- множество объектов, \( Y \)~--- конечное множество имен классов, множество
\( X\times Y \) является вероятностным пространством с плотностью распределения
\( p(x, y) = P(y)p(x\!\mid\!y) \). Вероятности появления объектов каждого из классов \( P_y = P(y) \)
называются априорными вероятностями классов. Плотности распределения \( p_y(x) = p(x\!\mid\!y) \)
называются функциями правдоподобия классов.

Рассмотрим произвольный алгоритм \( a \): \( X\to Y \). Он разбивает множество \( X \) на
непересекающиеся области \( A_y = \bigl\{x\in X\!\mid\! a(x) = y\bigr\} \), \( y\in Y \). Вероятность
того, что появится объект класса \( y \) и алгоритм \( a \) отнесет его к классу \( s \), равна
\( P_y P(A_s\!\mid\!y) \). Каждой паре \( (y, s)\in Y\times Y \) поставим в соответствие величину
потери \( \lambda_{ys} \) при отнесении объекта класса \( y \) к классу \( s \). Обычно полагают
\( \lambda_{yy}~=~0 \), и \( \lambda_{ys} > 0 \) при \( y\ne s \). Соотношения потерь на разных
классах, как правило, известны заранее.

Функционалом среднего риска называется ожидаемая величина потери при классификации объектов алгоритмом
\( a \):
\[
  R(a) = \sum_{y\in Y} \sum_{s\in Y} \lambda_{ys} P_y P(A_s\!\mid\! y).
\]
Если величина потерь одинакова для ошибок любого рода, \( \lambda_{ys} = \bigl[y\ne s\bigr] \), то
средний риск \( R(a) \) совпадает с вероятностью ошибки алгоритма \( a \).

Если известны априорные вероятности \( P_y \) и функции правдоподобия \( p_y(x) \), то минимум среднего
риска \( R(a) \) достигается алгоритмом
\begin{equation}
  a(x) = \arg\min_{s\in Y}\sum_{y\in Y}\lambda_{ys}P_yp_y(x).
  \label{eq:5}
\end{equation}

Часто можно полагать, что величина потери зависит только от истинной классификации объекта, но не от
того, к какому классу он был ошибочно отнесен. Итак, если \( P_y \) и \( p_y(x) \) известны, а
\( \lambda_{yy} = 0 \) и \( \lambda_{ys} \equiv \lambda_y \) для всех \( y \), \( s\in Y \), то минимум
среднего риска достигается алгоритмом
\begin{equation}
  a(x) = \arg\max_{y\in Y}\lambda_yP_yp_y(x).
  \label{eq:6}
\end{equation}
Это выражение называют байесовским решающим правилом.

Допустим, что объекты \( x\in X \) описываются \( n \) числовыми признаками \( f_j \):
\( X\to\RE \), \( j = 1, \ldots, n \). Обозначим через \( x = (\xi_1, \ldots, \xi_n) \)
произвольный элемент пространства объектов \( X = \RE^n \), где \( \xi_j = f_j(x) \).

Если предположить, что признаки \( f_1(x), \ldots, f_n(x) \) являются независимыми случайными
величинами, то функции правоподобия классов можно представить в виде
\begin{equation}
  p_y(x) = p_{y1}(\xi_1)\cdot\ldots\cdot p_{yn}(\xi_n), \quad y\in Y,
  \label{eq:7}
\end{equation}
где \( p_{yj}(\xi_j) \)~--- плотность распределения значений \( j \)-го признака для класса \( y \).
Это условие крайне редко выполняется на практике, поэтому алгоритмы, использующие
представление~\eqref{eq:7}, называются наивными байесовскими.

Подставив эмпирические оценки одномерных плотностей \( \hat{p}_{yj}(\xi) \) в~\eqref{eq:7} и затем
в~\eqref{eq:6}, получим алгоритм
\begin{equation}
  a(x) = \arg\max_{y\in Y}\left(\ln\lambda_y\hat{P}_y + \sum_{j = 1}^n \ln\hat{p}_{yj}(\xi_j)\right).
  \label{eq:8}
\end{equation}

Основные его преимущества~--- простота реализации и низкие вычислительные затраты при обучении и
классификации. В тех редких случаях, когда признаки (почти) независимы, наивный байесовский
классификатор (почти) оптимален.

Основной его недостаток~--- низкое качество классификации. Он используется либо как эталон при
экспериментальном сравнении алгоритмов, либо как элементарный <<строительный блок>> в алгоритмических
композициях.

Для более качественной классификации необходимо делать более сложные оценки плотности распределения
классов \( p_y(x) \).

\subsubsection{Непараметрический подход}
Непараметрические методы классификации основаны на локальном оценивании плотностей распределения
классов \( p_y(x) \) в окрестности классифицируемого объекта \( x\in X \). Для классификации объекта
\( x \) применяется основная формула~\eqref{eq:6}.

Локальное оценивание опирается на само определение плотности. Простейшие одномерные оценки могут
оказаться полезными на практике, в частности, при построении <<наивных>> байесовских
классификаторов~\eqref{eq:8}.

\begin{itemize}
  \itemsep -5pt
  \item[] \textbf{Дискретный случай}. Пусть \( X \)~--- конечное множество, причем \( \abs{X}\ll m \).
    Оценкой плотности служит гистограмма значений \( x_i \), встретившихся в выборке
    \( X^m = (x_i)^m_{i = 1} \):
    \begin{equation}
      \hat{p}(x) = \frac{1}{m}\sum_{i = 1}^m\bigl[x_i = x\bigr].
      \label{eq:9}
    \end{equation}
    
  \item[] \textbf{Одномерный непрерывный случай}. Пусть \( X = \RE \). Согласно определению плотности,
    \( p(x) = \lim_{h\to0} \frac{1}{2h} P[x - h, x + h] \), где \( P[a, b] \)~--- вероятностная мера
    отрезка \( [a, b] \). Соответственно, эмпирическая оценка плотности определяется как доля точек
    выборки, лежащих внутри отрезка \( [x - h, x + h] \), где \( h \)~--- неотрицательный параметр,
    называемый шириной окна:
    \begin{equation}
      \hat{p}_h(x) = \frac{1}{2mh}\sum_{i = 1}^m\left[\abs{x - x_i} < h\right].
      \label{eq:10}
    \end{equation}
    
    Функция \( \hat{p}_h(x) \) является кусочно-постоянной, что приводит к появлению широких зон
    неуверенности, в которых максимум~\eqref{eq:6} достигается одновременно для нескольких классов
    \( y\in Y \). Проблема решается с помощью локальной непараметрической оценки Парзена-Розенблатта:
    \begin{equation}
      \hat{p}_h(x) = \frac{1}{mh}\sum_{i = 1}^m K\left(\frac{x - x_i}{h}\right),
      \label{eq:11}
    \end{equation}
    где \( K(z) \)~--- функция, называемая ядром, четная и нормированная\linebreak
    \( \int K(z)\,dz = 1 \).
    Функция \( \hat{p}_h(x) \) обладает той же степенью гладкости, что и ядро \( K(z) \), и, благодаря
    нормировке, действительно может интерпретироваться как плотность вероятности:
    \( \int\hat{p}_h(x)\,dx = 1 \) при любом \( h \).
    
  \item[] \textbf{Многомерный непрерывный случай}. Пусть объекты описываются \( n \) числовыми
    признаками \( f_j \): \( X\to\RE \), \( j = 1, \ldots, n \). Тогда непараметрическая оценка
    плотности в точке \( x\in X \) записывается в следующем виде:
    \begin{equation}
      \hat{p}_h(x) = \frac{1}{m}\sum_{i = 1}^m\prod_{j = 1}^n\frac{1}{h_j}
      K\left(\frac{f_i(x) - f_j(x)}{h_j}\right).
      \label{eq:12}
    \end{equation}
    Таким образом, в каждой точке \( x_i \) многомерная плотность представляется в виде произведения
    одномерных плотностей.
  
  \item[] \textbf{Произвольное метрическое пространство}. Пусть на \( X \) задана функция расстояния
    \( \rho(x, x') \). Одномерная оценка Парзена-Розенблатта~\eqref{eq:10} обобщается и на этот случай:
    \begin{equation}
      \hat{p}_h(x) = \frac{1}{mV(h)}\sum_{i = 1}^m K\left(\frac{\rho(x, x_i)}{h}\right),
      \label{eq:13}
    \end{equation}
    где \( V(h) \)~--- нормирующий множитель, гарантирующий, что \( \hat{p}_h(x) \) действительно
    является плотностью. Сходимость оценки~\eqref{eq:13} доказана при некоторых дополнительных
    ограничениях на ядро \( K \) и метрику \( \rho \), причем скорость сходимости лишь немного хуже,
    чем в одномерном случае.
\end{itemize}

\subsubsection{Параметрический подход}
В параметрическом подходе предполагается, что плотность распределения выборки
\( X^m = \{x_1, \ldots, x_m\} \) известна с точностью до параметра, \( p(x) = \phi(x; \theta) \), где
\( \phi \)~--- фиксированная функция. Вектор параметров \( \theta \) оценивается по выборке \( X^m \) с
помощью принципа максимума правдоподобия.

Нормальный дискриминантный анализ~--- это специальный случай байесовской классификации, когда
предполагается, что плотности всех классов \( p_y(x) \), \( y\in Y \) являются многомерными
нормальными. Этот случай интересен и удобен тем, что задача оценивания параметров распределения по
выборке решается аналитически.

\begin{itemize}
  \itemsep -5pt
  \item[] \textbf{Многомерное нормальное распределение.}
    Пусть \( X = \RE^n \), то есть объекты описываются \( n \) числовыми признаками. Вероятностное
    распределение с плотностью
    \[
      N(x;\mu,\Sigma) = (2\pi)^{-\frac{n}{2}}\abs{\Sigma}^{-\frac{1}{2}}
      \exp\left(-\frac{1}{2}(x - \mu)^\T\Sigma^{-1}(x - \mu)\right), \quad (x\in \RE^n),
    \]
называется \( n \)-мерным нормальным (гауссовским) распределением с математическим ожиданием (центром)
\( \mu\in\RE^n \) и ковариационной матрицей \( \Sigma\in\RE^{n\times n} \). Предполагается, что матрица
\( \Sigma \) симметричная, невырожденная, положительно определенная.
\end{itemize}    

\subsection{Метод парзеновского окна}
Запишем парзеновскую оценку плотности~\eqref{eq:13} для каждого класса \( y\in Y \):
\begin{equation}
  \hat{p}_{y, h}(x) = \frac{1}{\l_yV(h)}\sum_{i = 1}^\l [y_i = y]
  K\left(\frac{\rho(x, x_i)}{h}\right),
  \label{eq:14}
\end{equation}
где \( K \)~--- ядро, \( h \)~--- ширина окна. Если нормирующий множитель \( V(h) \) не зависит
от \( y \), то в байесовском классификаторе~\eqref{eq:6} его можно убрать из-под знака
\( \arg\max \) и вообще не вычислять. Подставим оценку плотности~\eqref{eq:14} и оценку априорной
вероятности классов \( \hat{P}_y = \l_y/\l \) в формулу~\eqref{eq:6}:
\begin{equation}
  a(x; X^\l, h) = \arg\max_{y\in Y}\lambda_y\sum_{i = 1}^\l[y_i = y]
  K\left(\frac{\rho(x, x_i)}{h}\right).
  \label{eq:15}
\end{equation}
Выборка \( X^\l \) сохраняется <<как есть>> и играет роль параметра алгоритма. Если метрика
\( \rho \) фиксирована, то обучение парзеновского классификатора~\eqref{eq:14} сводится к подбору
ширины окна \( h \) и вида ядра \( K \).
\subsection{Линейный дискриминант Фишера}
Предположим, что ковариационные матрицы классов одинаковы и равны \( \Sigma \). Оценим
\( \hat{\Sigma} \) по всем \( \l \) обучающим объектам. С учётом поправки на смещённость,
\[
  \hat{\Sigma} = \frac{1}{\l - \abs{Y}}\sum_{i = 1}^\l (x_i - \hat{\mu}_{y_i})
  (x_i - \hat{\mu}_{y_i})^\T.
\]
Запишем подстановочный алгоритм:
\begin{equation}
  \begin{array}{rl}
    a(x) & = \arg\max_{y\in Y} (\lambda_yP_yp_y(x)) \\
    & = \ds\arg\max_{y\in Y}\left(\ln(\lambda_yP_y) -
  \frac{1}{2}\hat{\mu}_y^\T\hat{\Sigma}^{-1}\hat{\mu}_y + x^\T\hat{\Sigma}^{-1}
  \hat{\mu}_y\right) \\
    & = \arg\max_{y\in Y}\left(x^\T\alpha_y + \beta_y\right).
  \end{array}
\end{equation}

Этот алгоритм называется линейным дискриминантом Фишера. Он неплохо работает, когда формы классов
действительно близки к нормальным и не слишком сильно различаются. В этом случае линейное решающее
правило близко к оптимальному байесовскому, но существенно более устойчиво, чем квадратичное, и часто
обладает лучшей обобщающей способностью.

\subsection{EM--алгоритм}
Идея алгоритма заключается в следующем. Искусственно вводится вспомогательный вектор скрытых переменных
\( G \), обладающий двумя замечательными свойствами. С одной стороны, он может быть вычислен, если
известны значения вектора параметров \( \Theta \). С другой стороны, поиск максимума правдоподобия
сильно упрощается, если известны значения скрытых переменных.

EM-алгоритм состоит из итерационного повторения двух шагов. На E-шаге вычисляется ожидаемое значение
вектора скрытых переменных \( G \) по текущему приближению вектора параметров \( \Theta \). На М-шаге
решается задача максимизации правдоподобия и находится следующее приближение вектора \( \Theta \) по
текущим значениям векторов \( G \) и \( \Theta \).

\begin{enumerate}
  \itemsep -5pt
  \item[1:] Вычислить начальное приближение вектора параметров \( \Theta \);
  \item[2:] повторять
  \item[3:] \texttt{\( G \) := EStep(\( \Theta \))};
  \item[4:] \texttt{\( \Theta \) := MStep(\( \Theta \), \( G \))};
  \item[5:] пока \( \Theta \) и \( G \) не стабилизируются.
\end{enumerate}
Область применения этого алгоритма чрезвычайно широка~--- дискриминантный анализ, кластеризация,
восстановление пропусков в данных, обработка сигналов и изображений.

\subsubsection{E-шаг}
Обозначим через \( p(x, \theta_j) \) плотность вероятности того, что объект \( x \) принадлежит
\( j \)-му классу. По формуле условной вероятности
\[
  p(x, \theta_j) = p(x) P(\theta_j\!\mid\!x) = w_jp_j(x).
\]
Введём обозначение \( g_{ij} \equiv P(\theta_j\!\mid\!x_i) \). Это неизвестная апостериорная
вероятность того, что обучающий объект \( x_i \) принадлежит \( j \)-му классу. Возьмём эти
величины в качестве скрытых переменных. Обозначим \( G = (g_{ij})_{m\times k} = (g_1, \ldots , g_j) \),
где \( g_j \)~--- \( j \)-й столбец матрицы \( G \). Каждый объект обязательно принадлежит какому-то
классу, поэтому справедлива формула полной вероятности:
\[
  \sum_{j = 1}^k g_{ij} = 1 \quad \text{для всех } i = 1, \ldots, \l.
\]
Зная параметры классов \( w_j \), \( \theta_j \), легко вычислить \( g_{ij} \) по формуле Байеса:
\begin{equation}
  g_{ij} = \frac{w_jp_j(x_i)}{\sum_{s = 1}^k w_sp_s(x_i)} \quad \text{для всех } i, j.
  \label{eq:2.17}
\end{equation}
В этом и заключается E-шаг алгоритма EM.

\subsubsection{M-шаг}
M-шаг сводится к вычислению весов классов \( w_j \) как средних арифметических:
\begin{equation}
  w_j = \frac{1}{m}\sum_{i = 1}^m\frac{w_jp_j(x_i)}{\sum_{s = 1}^k w_sp_s(x_i)} =
  \frac{1}{m}\sum_{i = 1}^m g_{ij}, \quad j = 1, \ldots, k
  \label{2:19}
\end{equation}
и оцениванию параметров классов \( \theta_j \) путём решения \( k \) независимых оптимизационных
задач:
\begin{equation}
  \theta_j = \arg\max_\theta\sum_{i = 1}^m g_{ij}\ln\phi(x_i; \theta), \quad j = 1, \ldots, k.
  \label{2:20}
\end{equation}

ЕМ-алгоритм с фиксированным числом классов\\
\rule{\textwidth}{1pt}\\
\textbf{Вход:}\\
\indent выборка \( X^m = \{x_1,\ldots,x_m\} \);\\
\indent \( k \)~--- число классов;\\
\indent \( \Theta = (w_j, \theta_j)_{j = 1}^k \)~--- начальное приближение параметров;\\
\indent \( \delta \)~--- параметр критерия останова;\\
\textbf{Выход:}\\
\indent \( \Theta^* = (w_j, \theta_j)_{j = 1}^k \)~--- оптимизированный вектор параметров.\\
\rule{\textwidth}{.5pt}
\textbf{повторять:}\\
\indent E-шаг:\\
\indent для всех \( i = 1, \ldots, m \), \( j = 1, \ldots, k \)
\[
  g_{ij}^0 = g_{ij}; \quad g_{ij} = \frac{w_j\phi(x_i; \theta_j}{\sum_{s = 1}^kw_s\phi(x_i; \theta_s)};
\]
\indent M-шаг:\\
\indent для всех \( j = 1, \ldots, k \)
\[
  \theta_j = \arg\max_\theta\sum_{i = 1}^m g_{ij}\ln\phi(x_i; \theta); \quad w_j = \frac{1}{m}\sum_{i = 1}^m g_{ij};
\]
\textbf{пока} \( \max_{i, j}\abs{g_{ij} - g_{ij}^0} > \delta \);\\
\textbf{вернуть} \( (w_j, \theta_j)_{j = 1}^k \).\\
\rule{\textwidth}{1pt}

\subsection{Метод ближайшего соседа}
Пусть на множестве объектов \( X \) задана функция расстояния \( \rho \): \( X\times X\to [0, \infty) \).
Существует целевая зависимость \( y^* \): \( X\to Y \), значения которой известны только на объектах
обучающей выборки \( X^\l = (x_i, y_i)_{i = 1}^\l \), \( y_i = y_i^*(x_i) \). Множество классов \( Y \)
конечно. Требуется построить классификатор \( a \): \( X\to Y \), аппроксимирующий целевую зависимость
\( y^*(x) \) на всём множестве \( X \).

Алгоритм ближайшего соседа относит классифицируемый объект \( u\in X^\l \) к тому классу, которому
принадлежит ближайший обучающий объект:
\[
  w(i,u) = [i = 1]; \quad a(u; X^\l)= y^{(1)}_u.
\]
Этот алгоритм является, по всей видимости, самым простым классификатором.
Обучение алгоритма сводится к запоминанию выборки \( X^\l \). Единственное достоинство этого
алгоритма~--- простота реализации. Недостатков гораздо больше:
\begin{itemize}
  \item Неустойчивость к погрешностям. Если среди обучающих объектов есть выброс~--- объект, находящийся
    в окружении объектов чужого класса, то не только он сам будет классифицирован неверно, но и те
    окружающие его объекты, для которых он окажется ближайшим.
  \item Отсутствие параметров, которые можно было бы настраивать по выборке. Алгоритм полностью зависит
    от того, насколько удачно выбрана метрика \( \rho \).
  \item В результате~--- низкое качество классификации.
\end{itemize}

Чтобы сгладить влияние выбросов, будем относить объект \( u \) к тому классу, элементов которого окажется
больше среди \( k \) ближайших соседей \( x^{(i)}_u \), \( i = 1, \ldots, k \):
\[
  w(i, u) = [i\le k]; \quad a(u; X^\l, k) = \arg\max_{y\in Y}\sum_{i = 1}^k[y^{(i)}_u = y].
\]
При \( k = 1 \) этот алгоритм совпадает с предыдущим, следовательно, неустойчив к шуму. При
\( k = \l \), наоборот, он чрезмерно устойчив и вырождается в константу. Таким образом, крайние
значения \( k \) нежелательны.

\subsection{Метод опорных векторов}
Метод опорных векторов основан на концепции гиперплоскостей, которые определяют границы гиперповерхностей.
Разделяющая гиперплоскость~--- это гиперплоскость, которая отделяет группу объектов, имеющих различную
классовую принадлежность.
Метод опорных векторов обладает несколькими замечательными свойствами. Во-первых, обучение метода
сводится к задаче квадратичного программирования, имеющей единственное решение, которое вычисляется
достаточно эффективно даже на выборках в сотни тысяч объектов. Во-вторых, решение обладает свойством
разреженности: положение оптимальной разделяющей гиперплоскости зависит лишь от небольшой доли
обучающих объектов. Они называются опорными векторами; остальные объекты фактически не задействуются.
На случай нелинейных разделяющих поверхностей метод обобщается введением функции ядра.

Рассмотрим задачу классификации на два непересекающихся класса, в которой объекты описываются
\( n \)-мерными вещественными векторами: \( X = \RE^n \), \( Y = \{-1, +1\} \).
Будемстроить линейный пороговый классификатор:
\[
  a(x) = \sign\left(\sum_{j = 1}^n w_jx^j - w_0\right) = \sign\Bigl(\bigl\langle w, x\bigr\rangle - w_0\Bigr),
\]
где \( x = (x^1, \ldots, x^n) \)~--- признаковое описание объекта \( x \); вектор
\( w = (w^1, \ldots, w^n)\in\RE^n \) и скалярный порог \( w_0\in\RE \) являются параметрами алгоритма.
Уравнение \( \bigl\langle w, x\bigr\rangle = w_0 \) описывает гиперплоскость, разделяющую классы в
пространстве \( \RE^n \). Пусть выборка \( X^\l = (x_i, y_i)_{i = 1}^\l \) линейно разделима и существуют
значения \( w \), \( w_0 \), при которых функционал числа ошибок
\[
  Q(w, w_0) = \sum_{i = 1}^\l \left[y_1\Bigl(\bigl\langle w, x\bigr\rangle - w_0\Bigr)\le 0\right]
\]
принимает нулевое значение. Потребуем,чтобы разделяющая гиперплоскость максимально далеко отстояла от
ближайших к ней точек обоих классов.

Параметры линейного порогового классификатора определены с точностью до нормировки: алгоритм \( a(x) \)
не изменится, если \( w \) и \( w_0 \) одновременно умножить на одну и ту же положительную константу.
Удобно выбрать эту константу таким образом, чтобы выполнялось условие
\begin{equation}
  \min_{i = 1,\ldots,\l}y_1\Bigl(\bigl\langle w, x_i\bigr\rangle - w_0\Bigr) = 1.
  \label{eq:4.15}
\end{equation}

Множество точек \( \Bigl\{ x\colon -1\le\bigl\langle w, x_i\bigr\rangle - w_0\le 1\Bigr\} \) описывает
полосу, разделяющую классы. Ни один из объектов обучающей выборки не попадает внутрь этой полосы.
Границами полосы служат две параллельные гиперплоскости с вектором нормали \( w \). Разделяющая
гиперплоскость проходит ровно посередине между ними. Объекты, ближайшие к разделяющей гиперплоскости,
лежат на границах полосы, и именно на них достигается минимум~\eqref{eq:4.15}.

\section{Задачи регрессии}
Задачу обучения по прецедентам при \( Y = \RE \) принято называть задачей восстановления регрессии.
Задано пространство объектов \( X \) и множество возможных ответов \( Y \). Существует неизвестная
целевая зависимость \( y^* \): \( X\to Y \), значения которой известны только на объектах обучающей
выборки \( X^\l = (x_i, y_i)^\l_{i = 1} \), \( y_i = y^*(x_i) \). Требуется построить алгоритм, который
в данной задаче принято называть <<функцией регрессии>> \( a \): \( X\to Y \), аппроксимирующий целевую
зависимость \( y^* \).

\subsection{Метод наименьших квадратов}
Пусть задана модель регрессии~--- параметрическое семейство функций \( g(x, \alpha) \), где
\( \alpha\in\RE^p \)~--- вектор параметров модели. Определим функционал качества аппроксимации целевой
зависимости на выборке \( X^\l \) как сумму квадратов ошибок:
\begin{equation}
  Q(\alpha, X^\l) = \sum_{i = 1}^\l (g(x_i, \alpha) - y_i)^2.
  \label{eq:5.1}
\end{equation}

Обучение по методу наименьших квадратов состоит в том, чтобы найти вектор параметров \( \alpha^* \),
при котором достигается минимум среднего квадрата ошибки на заданной обучающей выборке \( X^\l \):
\begin{equation}
  \alpha^* = \arg\min_{\alpha\in\RE^p} Q(\alpha, X^\l).
  \label{eq:5.2}
\end{equation}

Стандартный способ решения этой оптимизационной задачи~--- воспользоваться необходимым условием
минимума. Если функция \( g(x, \alpha) \) достаточное число раз дифференцируема по \( \alpha \), то в
точке минимума выполняется система \( p \) уравнений относительно \( p \) неизвестных:
\begin{equation}
  \pder{Q}{\alpha}(\alpha, X^\l) = 2\sum_{i = 1}^\l(g(x_i, \alpha) - y_i)\pder{g}{\alpha}(x_i, \alpha) = 0.
  \label{eq:5.3}
\end{equation}

\subsection{Метод ядерного сглаживания}
Возьмём самую простую модель регрессии, какая только возможна~--- константу \( g(x, \alpha) = \alpha \),
\( \alpha\in\RE \). Но при этом, чтобы не получить тривиального решения, введём веса объектов \( w_i(x) \),
зависящие от того объекта \( x \), в котором мы собираемся вычислять значение \( a(x) = g(x, \alpha) \).

Чтобы вычислить значение \( a(x) = \alpha \) для произвольного \( x\in X \), воспользуемся методом
наименьших квадратов~\eqref{eq:5.1}:
\[
  Q(\alpha; X^\l) = \sum_{i = 1}^\l w_i(x)(\alpha - y_i)^2\to\min_{\alpha\in\RE}.
\]

Зададим веса \( w_i \) обучающих объектов так, чтобы они убывали по мере увеличения расстояния
\( \rho(x, x_i) \). Для этого введём невозрастающую, гладкую, ограниченную функцию \( K \), называемую
ядром:
\[
  w_i(x) = K\left(\frac{\rho(x, x_i)}{h}\right).
\]
Параметр \( h \) называется шириной ядра. Чем меньше \( h \), тем быстрее будут убывать веса
\( w_i(x) \) по мере удаления \( x_i \) от \( x \).

Приравняв к нулю производную \( \ds\pder{Q}{\alpha} = 0 \), получим формулу ядерного сглаживания:
\begin{equation}
  \alpha_h(x; X^\l) = \frac{\sum_{i=1}^\l y_iw_i(x)}{\sum_{i=1}^\l w_i(x)} =
  \frac{\sum_{i=1}^\l y_iK\left(\frac{\rho(x, x_i)}{h}\right)}{\sum_{i=1}^\l K\left(\frac{\rho(x, x_i)}{h}\right)}.
  \label{eq:5.4}
\end{equation}

Ядерное сглаживание~--- это довольно простой метод с точки зрения реализации. Обучение алгоритма
\( a_h(x; X^\l) \) сводится к запоминанию выборки, подбору ядра \( K \) и ширины окна \( h \).

Выбор ядра \( K \) мало влияет на точность аппроксимации, но определяющим образом влияет на степень
гладкости функции \( a_h(x) \).

Выбор ширины окна \( h \) решающим образом влияет на качество восстановления зависимости. При слишком
узком окне \( (h\to 0) \) функция \( a_h(x) \) стремится пройти через все точки выборки, реагируя на шум
и претерпевая резкие скачки. При слишком широком окне функция чрезмерно сглаживается и в пределе
\( h\to\infty \) вырождается в константу.

\section{Задачи кластеризации}
\subsection{Метод k-средних}
Наиболее простой, но в то же время достаточно неточный метод кластеризации в классической реализации.
Он разбивает множество элементов векторного пространства на заранее известное число кластеров \( k \).
Действие алгоритма таково, что он стремится минимизировать среднеквадратичное отклонение на точках
каждого кластера. Основная идея заключается в том, что на каждой итерации перевычисляется центр масс
для каждого кластера, полученного на предыдущем шаге, затем векторы разбиваются на кластеры вновь в
соответствии с тем, какой из новых центров оказался ближе по выбранной метрике. Алгоритм завершается,
когда на какой-то итерации не происходит изменения кластеров.

Проблемы алгоритма \( k \)-средних:
\begin{itemize}
  \itemsep -5pt
  \item необходимо заранее знать количество кластеров;
  \item алгоритм очень чувствителен к выбору начальных центров кластеров. Классический вариант подразумевает случайный выбор кластеров.
\end{itemize}

Алгоритм:\\
\rule{\textwidth}{1pt}\\
сформировать начальное приближение центров всех кластеров \( y\in Y \):\\
\( \mu_y \)~--- наиболее удаленные друг от друга объекты выборки;\\
\textbf{повторять}\\
\indent отнести каждый объект к ближайшему центру:
\[
  y_i = \arg\min_{y\in Y}\rho(x_i, \mu_y), \quad i = 1, \ldots, \l;
\]
\indent вычислить новое положение центров:
\[
  \mu_{yj} = \frac{\sum_{i=1}^\l [y_i = y]f_j(x_i)}{\sum_{i=1}^\l[y_i = y]}, \quad y\in Y, j = 1,\ldots, n;
\]
\textbf{пока} \( y_i \) не перестанут изменяться.\\
\rule{\textwidth}{1pt}

\subsection{Иерархический метод}
Среди алгоритмов иерархической кластеризации выделяются два основных типа: восходящие и нисходящие
алгоритмы. Нисходящие алгоритмы работают по принципу <<сверху--вниз>>: в начале все объекты помещаются
в один кластер, который затем разбивается на все более мелкие кластеры. Более распространены восходящие
алгоритмы, которые в начале работы помещают каждый объект в отдельный кластер, а затем объединяют
кластеры во все более крупные, пока все объекты выборки не будут содержаться в одном кластере. Таким
образом строится система вложенных разбиений. Результаты таких алгоритмов обычно представляют в виде
дерева~--- дендрограммы.

К недостатку иерархических алгоритмов можно отнести систему полных разбиений, которая может являться
излишней в контексте решаемой задачи.

Алгоритм восходящей иерархической кластеризации:\\
\rule{\textwidth}{1pt}\\
сначала все кластеры одноэлементные:
\[
  t = 1; \quad C_t = \bigl\{\{x_1\}, \ldots, \{ x_\l \}\bigr\}; \quad R(\{ x_i \}, \{ x_j \}) = \rho(x_i, x_j);
\]
\textbf{для всех} \( t = 2, \ldots, \l \) (\( t \)~--- номер итерации):\\
\indent найти в \( C_{t - 1} \) два ближайших кластера:
\[
  (U, V) = \arg\min_{U\ne V} R(U, V); R_t = R(U, V);
\]
\indent слить их в один кластер:
\[
  W = U\cup V; C_t = C_{t - 1}\cup\{ W \} \backslash \{ U, V \};
\]
\indent\textbf{для всех} \( S\in C_t \)\\
\indent\indent вычислить \( R(W, S) \).\\
\rule{\textwidth}{1pt}

\subsection{Выделение связных компонент}
В алгоритме выделения связных компонент задается входной параметр \( R \) и в графе удаляются все
ребра, для которых <<расстояния>> больше \( R \). Соединенными остаются только наиболее близкие пары
объектов. Смысл алгоритма заключается в том, чтобы подобрать такое значение \( R \), лежащее в диапазон
всех <<расстояний>>, при котором граф <<развалится>> на несколько связных компонент. Полученные
компоненты и есть кластеры.

Для подбора параметра \( R \) обычно строится гистограмма распределений попарных расстояний. В задачах
с хорошо выраженной кластерной структурой данных на гистограмме будет два пика~--- один соответствует
внутрикластерным расстояниям, второй~--- межкластерным расстояния. Параметр \( R \) подбирается из зоны
минимума между этими пиками. При этом управлять количеством кластеров при помощи порога расстояния
довольно затруднительно.

\chapter{Направление развития}
\section{Глубинное обучение}
Методы глубинного обучения являются попыткой реинкарнации нейронных сетей, с конца 80-ых гг. прошлого
века переживающих кризис. Причинами кризиса традиционных нейронных сетей стали:
\begin{itemize}
  \item критическая зависимость качества настройки весов сети от выбора начального приближения и, как
    следствие, проблемы с воспроизводимостью <<успешных>> результатов, публиковавшихся в научных журналах;
  \item большая подверженность переобучению вкупе со слабыми возможностями контроля обобщающей
    способности сети;
  \item большое количество локальных минимумов функционала качества, большинство из которых оказывались
    плохими.
\end{itemize}

С другой стороны, неоспоримой сильной стороной нейронных сетей явилось открытие метода обратного
распространения ошибки, позволявшего отслеживать влияние внутренних слоев сети на качество прогноза
скрытых переменных объектов обучающей выборки.

Во второй половине 00-ых гг. стало активно развиваться направление, получившее название глубинного
обучения. В его основе лежат нейроные сети, претерпевшие значительные изменения:
\begin{itemize}
  \item Глубиннное обучение строит не дискриминативные, а порождающие модели, в которых моделируется
    общее распределение \( p(X;T;\vec{w}) \), в отличие от дискриминативных моделей, позволяющее,
    например, генерировать новые объекты.
  \item В наиболее распространенной постановке все переменные объектов предполагаются бинарными. Это
    облегчает моделирование зависимостей между переменными объекта.
  \item Каждый слой сети сначала обучается независимо, проходя процедуру предобучения. Это позволяет
    <<нащупать>> хорошее начальное приближение для последующего запуска алгоритма обратного распространения
    ошибки. Каждый слой, в зависимости от выбранной модели, представляет собой ограниченную машину
    Больцмана или сверточную сеть.
  \item Для обучения используются сотни тысяч и миллионы объектов. Такие гигантские выборки позволяют
    настраивать сети с десятками тысяч параметров, без риска переобучения. Обученные таким образом сети,
    не просто позволяют моделировать сложные объекты, но и генерируют в процессе обучения информативные
    признаковые описания, которые могут быть использованы другими, более простыми алгоритмами машинного
    обучения в качестве наблюдаемых переменных объекта.
\end{itemize}

\section{Непараметрические байесовские методы}
Традиционно, методы непараметрической статистики определялись как раздел статистики, в которой число
параметров, описывающих данные не фиксировано, а растет с ростом числа объектов.
Для примера можно рассмотреть задачу определения числа кластеров в постоянно растущей выборке объектов.
Данная задача тем более актуальна, что общепринятых методов определения, из скольки же кластеров состоит
даже зафиксированная выборка, на сегодняшний день не существует. Чем больше объектов поступает в наше
распоряжение, тем с большим разрешением мы можем находить в них структуру, выделяя кластеры схожих между
собой объектов. В случае достаточно неоднородной выборки число кластеров должно постепенно увеличиваться
по мере поступления новых объектов. В непараметрическом случае, нам необходимо задать распределение
над всевозможными разбиениями произвольного количества объектов. Такое распределение задается с помощью
случайных процессов. В данном случае, это процесс Дирихле. С его помощью, удается не только рассчитать
для любого разбиения произвольного числа объектов на кластеры его априорную вероятность, но и учесть
характеристики объектов, чтобы перейти к апостериорному распределению на всевозможные разбиения. Как
это часто бывает при применении байесовских методов, апостериорное распределение имеет острый пик,
который соответствует устойчивому разбиению выборки объектов на некоторое число кластеров.

\section{Обучение с подкреплением}
Обучение с подкреплением предназначено для обучения агентов в условиях неопределенности, порождаемой
как неполнотой информации об окружающей обстановке, так и возможными действиями других агентов. В
зависимости от текущего состояния среды и действий агентов рассчитывается функция выгоды, которую
получит агент в следующий момент времени.

Важным достоинством алгоритмов обучения с подкреплением является возможность обучения агента <<с нуля>>
за счет балансируемого сочетания режимов <<исследование--использование>> и выучивания стратегий,
позволяющих жертвовать малым сейчас ради получения большей выгоды в дальнейшем. Алгоритмы обучения с
подкреплением нашли широкое применение не только в таких традиционных областях как робототехника, но и,
например, на фондовых рынках.

\section{Анализ больших объемов данных}
Традиционные методы машинного обучения не всегда применимы для анализа выборок такого размера, поскольку
в них зачастую неявно предполагается, что вся выборка помещается в памяти компьютера, или же они имеют
недостаточно высокие показатели скорости роста вычислительной сложности в зависимости от размера
выборки). Для преодоления этих ограничений часто используются приемы из следующих категорий:
\begin{itemize}
  \item Распараллеливание. Независимые части алгоритма могут выполняться параллельными обработчиками и
    в произвольном порядке. В некоторых случаях параллельной реализации классичесского алгоритма может
    быть достаточно для конкретной задачи.
  \item Аппроксимация. Известно, что многие сложные задачи могут быть решены приближенно с достаточно
    большой точностью, достаточной для данного эксперимента.
  \item Стохастичность. При наличии большого числа независимых объектов в выборке, многие необходимые
    статистики могут быть оценены по случайной подвыборке, при этом сохраняются теоретические гарантии
    оптимальности и сходимости алгоритма.
\end{itemize}

В последнее время стали также набирать популярность так называемые потоковые алгоритмы, способные
обучаться инкрементально в режиме реального времени на постоянно поступающих данных без необходимости
хранить их где-либо в памяти. Спрос на них возникает, как правило, в приложениях, где данные поступают
в таких количествах и с такой скоростью, что нет никакой возможности сохранять их, по крайней мере,
надолго. С такими задачами анализа данных сталкиваются, например, исследователи в ЦЕРНе, где данные
генерируются со скоростью более 700 мегабайт в секунду.

\chapter{Библиотеки}
\emph{Microsoft Azure Machine Learning}~--- инфраструктура облачных вычислений от компании Microsoft,
представляющая собой обновленную версию MS Azure. В контексте машинного обучения инструмент представляет
собой платформу, которая позволяет вне зависимости от качества данных строить решения прямо <<на облаке>>
и с легкостью создавать на их основе BI-приложения.

\emph{RapidMiner}~--- один из самых известных инструментов анализа данных. ПО разрабатывалось в целях
машинного обучения, так что на сегодня многие пользователи хорошо знакомы с его преимуществами. Среди них~---
удобный графический интерфейс с функцией <<перетаскивания>> потоков данных.

\emph{Apache Mahout}~--- проект фонда Apache и часть экосистемы Apache Hadoop, предназначенная для
реализации распределенных или предусматривающих возможность масштабирования алгоритмов машинного обучения.
ПО с открытым кодом главным образом ориентировано на алгоритмы совместной фильтрации, кластеризации и
классификации.

\emph{Caffe} представляет собой библиотеку на языке C++, реализующую алгоритмы глубокого обучения, которая
была разработана с упором на такие важные характеристики, как поддержание уровня чистоты данных, их
читабельность и скорость обработки.

Открытый код, поддержка Python и интеграция с MATLAB, а также высокая скорость работы позволили Caffe найти себе широкое применение, в том числе, и в коммерческой среде.

\emph{OpenCV}~--- библиотека с открытым кодом, реализованная на C/C++ и перенесенная на Python, Java и
MATLAB. OpenCV предлагает широкий инструментарий для работы с визуализацией~--- в том числе, и в целях
машинного обучения, причем библиотека работает с большинством операционных систем, включая мобильные iOS и Android.

\emph{Torch}~--- научный вычислительный фреймвок, имеющий широкую поддержку алгоритмов машинного обучения,
использующих для работы GPU. Он прост в использовании и довольно эффективен благодаря скриптовому языку
LuaJIT и реализации на C/CUDA.

\emph{Weka}~--- библиотека алгоритмов машинного обучения для решения задач интеллектуального анализа
данных. Система позволяет непосредственно применять алгоритмы к выборкам данных, а также вызывать
алгоритмы из программ на языке Java.

\emph{Theano}~--- это библиотека на Python и оптимизирующий компилятор, которые позволяют определять,
оптимизировать и вычислять математические выражения эффективно используя многомерные массивы. Библиотека
тесно интегрирована с NumPy, поддерживает использование GPU, динамически генерирует код на C.

\emph{TensorFlow}~--- система с открытым исходным кодом от Google. TensorFlow способна создавать и
обучать нейронные сети. Среди преимуществ системы TensorFlow~--- простое масштабирование и возможность
использовать ее в качестве инструмента анализа сложных данных. Система предоставляет унифицированный
интерфейс для различных методов машинного обучения, позволяющий строить модели в виде графа и
включающий в себя имплементацию методов оптимизации этих моделей.

\emph{Scikit-learn}~--- отлично документированная библиотека на Python, в которой реализовано большое
количество алгоритмов машинного обучения. Помимо этого библиотека содержит различные инструменты
начальной и конечной обработки данных и визуализации.

\chapter{Литература, курсы, конференции}
\begin{enumerate}
  \item machinelearning.ru~--- Профессиональный информационно-аналитический ресурс, посвященный машинному
    обучению, распознаванию образов и интеллектуальному анализу данных.
  \item habrahabr.ru/hub/machine\_learning~--- Хаб <<Машинное обучение>>.
  \item datareview.info~--- информационно-образовательный портал, посвященный вопросам анализа и
    обработки данных.
  \item yury.name/internet~--- Юрий Лифшиц~-- курс <<Алгоритмы для Интернета>>.
  \item intuit.ru/studies/courses/13844/1241/info~--- Курс <<Машинное обучение>> от Школы Анализа
    Данных (Яндекс).
  \item uic.unn.ru/\( \sim \)zny/ml~--- Н. Ю. Золотых~-- курс 	
<<Машинное обучение>>.
  \item mmro.ru~--- конференции «Математические методы распознавания образов» и «Интеллектуализация
    обработки информации».
  \item machinelearning.org/icml.html~--- International Conference on Machine\linebreak Learning.
  \item nips.cc~--- конференция Neural Information Processing Systems.
  \item learningtheory.org~--- конференция Computational Learning Theory.
\end{enumerate}

\newpage
\renewcommand{\refname}{Список использованной литературы}
\begin{thebibliography}{9}
\addcontentsline{toc}{chapter}{Список использованной литературы}
  \bibitem{1} Воронцов, К. В. Математические методы обучения по прецедентам (теория обучения машин). Курс лекций [Электронный ресурс]~--- Режим доступа:
  \emindent\url{http://www.machinelearning.ru/wiki/images/6/6d/Voron-ML-1.pdf}
%--------------------------------------------------------------  
  \bibitem{2} MachineLearning.ru~--- Профессиональный информационно-аналитический ресурс, посвященный машинному
обучению, распознаванию образов и интеллектуальному анализу данных [Электронный ресурс]~--- Режим доступа:\\
  \emindent\url{http://www.machinelearning.ru/}
%--------------------------------------------------------------
  \bibitem{3} Обзор алгоритмов кластеризации данных [Электронный ресурс]~// Хабрахабр~--- Режим доступа:\\
  \emindent\url{https://habrahabr.ru/post/101338/}
%--------------------------------------------------------------
  \bibitem{4} Введение в машинное обучение с помощью Python и Scikit-Learn [Электронный ресурс]~// Хабрахабр~--- Режим доступа:\\
  \emindent\url{https://habrahabr.ru/company/mlclass/blog/247751/}
%--------------------------------------------------------------
  \bibitem{5} Google открыла для всех библиотеку машинного обучения TensorFlow [Электронный ресурс]~// Хабрахабр~--- Режим доступа:\\
  \emindent\url{https://geektimes.ru/post/265516/}
%--------------------------------------------------------------
  \bibitem{6} Машинное обучение для самых маленьких [Электронный ресурс]~// SavePearlHarbor~-- Ещё одна копия хабора~--- Режим доступа:\\
  \emindent\url{http://savepearlharbor.com/?p=189178}
%--------------------------------------------------------------
  \bibitem{7} Кластеризация: алгоритмы k-means и c-means [Электронный ресурс]~// Хабрахабр~--- Режим доступа:\\
  \emindent\url{https://habrahabr.ru/post/67078/}
%--------------------------------------------------------------
  \bibitem{8} TОП-5 инструментов для машинного обучения~// DataReview.info~--- Режим доступа:\\
  \emindent\url{http://datareview.info/article/top-5-instrumentov-dlya-mashinnogo-obucheniya/}
%--------------------------------------------------------------
  \bibitem{9} Золотых, Н. Ю. Машинное обучение и анализ данных [Электронный ресурс]~--- Режим доступа:\\
  \emindent\url{http://www.uic.unn.ru/~zny/ml/Lectures/Old/ml_pres_2015a.pdf}
%--------------------------------------------------------------
  \bibitem{10} Воронцов, К. В. Методы кластеризации [Электронный ресурс]~--- Режим доступа:\\
  \emindent\url{http://www.machinelearning.ru/wiki/images/2/28/Voron-ML-Clustering-slides.pdf}
%--------------------------------------------------------------
  \bibitem{11} Ветров, Д. П. Машинное обучение~-- состояние и перспективы [Электронный ресурс]~--- Режим доступа:\\
  \emindent\url{http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.402.8676}
%--------------------------------------------------------------
  \bibitem{12} Классификация [Электронный ресурс]~// MachineLearning.ru~--- Режим доступа:\\
  \emindent\href{http://www.machinelearning.ru/wiki/index.php?title=%D0%9A%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F}{\small http://www.machinelearning.ru/wiki/index.php?title=Классификация}
\end{thebibliography}
